# -*- coding: utf-8 -*-
"""submit-code.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CCK56b7CZsJcpsibKBCXFnmsm9BkLPsB
"""

import os
import numpy as np
import cv2
import tensorflow as tf
from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Concatenate, Input
from tensorflow.keras.models import Model
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Parameters
image_size = 256  # Resize images to 256x256

# Path to images
image_folder = 'path to the images folder '  # Adjust this path
mask_save_folder = 'path to save the images folder'  # Adjust Folder to save Segmented Images

# Create folder if it doesn't exist
os.makedirs(mask_save_folder, exist_ok=True)

# Function to load images and masks
def load_data(image_folder, img_size):
    images = []
    masks = []
    filenames = []
    for filename in os.listdir(image_folder):
        img_path = os.path.join(image_folder, filename)
        img = cv2.imread(img_path)

        if img is None:
            print(f"Failed to load image: {img_path}")
            continue

        # Convert to HSV and create mask for green color
        hsv_img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
        mask = cv2.inRange(hsv_img, (35, 40, 40), (85, 255, 255))  # Green color range in HSV

        img = cv2.resize(img, (img_size, img_size))
        mask = cv2.resize(mask, (img_size, img_size))

        images.append(img)
        masks.append(mask)
        filenames.append(filename)

    images = np.array(images)
    masks = np.array(masks)
    masks = masks[..., np.newaxis]  # Add channel dimension
    return images, masks, filenames

# Load dataset
images, masks, filenames = load_data(image_folder, image_size)

# Split into train and test sets
X_train, X_test, y_train, y_test, filenames_train, filenames_test = train_test_split(images, masks, filenames, test_size=0.2, random_state=42)

# Data augmentation
data_gen_args = dict(rotation_range=90.,
                    width_shift_range=0.1,
                    height_shift_range=0.1,
                    shear_range=0.5,
                    zoom_range=0.2,
                    horizontal_flip=True,
                    fill_mode='nearest')
image_datagen = ImageDataGenerator(**data_gen_args)
mask_datagen = ImageDataGenerator(**data_gen_args)

# Custom data generator
def custom_data_generator(image_datagen, mask_datagen, X_train, y_train, batch_size):
    image_generator = image_datagen.flow(X_train, batch_size=batch_size, seed=42)
    mask_generator = mask_datagen.flow(y_train, batch_size=batch_size, seed=42)

    while True:
        X_batch = next(image_generator)
        y_batch = next(mask_generator)
        yield X_batch, y_batch

# U-Net Model
def unet_model(input_size=(256, 256, 3)):
    inputs = Input(input_size)

    # Encoder
    conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)
    conv1 = Conv2D(64, 3, activation='relu', padding='same')(conv1)
    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)

    conv2 = Conv2D(128, 3, activation='relu', padding='same')(pool1)
    conv2 = Conv2D(128, 3, activation='relu', padding='same')(conv2)
    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)

    conv3 = Conv2D(256, 3, activation='relu', padding='same')(pool2)
    conv3 = Conv2D(256, 3, activation='relu', padding='same')(conv3)
    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)

    conv4 = Conv2D(512, 3, activation='relu', padding='same')(pool3)
    conv4 = Conv2D(512, 3, activation='relu', padding='same')(conv4)
    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)

    conv5 = Conv2D(1024, 3, activation='relu', padding='same')(pool4)
    conv5 = Conv2D(1024, 3, activation='relu', padding='same')(conv5)

    # Decoder
    up6 = UpSampling2D(size=(2, 2))(conv5)
    up6 = Concatenate()([up6, conv4])
    conv6 = Conv2D(512, 3, activation='relu', padding='same')(up6)
    conv6 = Conv2D(512, 3, activation='relu', padding='same')(conv6)

    up7 = UpSampling2D(size=(2, 2))(conv6)
    up7 = Concatenate()([up7, conv3])
    conv7 = Conv2D(256, 3, activation='relu', padding='same')(up7)
    conv7 = Conv2D(256, 3, activation='relu', padding='same')(conv7)

    up8 = UpSampling2D(size=(2, 2))(conv7)
    up8 = Concatenate()([up8, conv2])
    conv8 = Conv2D(128, 3, activation='relu', padding='same')(up8)
    conv8 = Conv2D(128, 3, activation='relu', padding='same')(conv8)

    up9 = UpSampling2D(size=(2, 2))(conv8)
    up9 = Concatenate()([up9, conv1])
    conv9 = Conv2D(64, 3, activation='relu', padding='same')(up9)
    conv9 = Conv2D(64, 3, activation='relu', padding='same')(conv9)

    conv10 = Conv2D(1, 1, activation='sigmoid')(conv9)

    model = Model(inputs=[inputs], outputs=[conv10])
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    return model

# Initialize and train model
model = unet_model()
model.summary()

# Fit model using custom data generator
batch_size = 8
epochs = 50
train_generator = custom_data_generator(image_datagen, mask_datagen, X_train, y_train, batch_size)

model.fit(train_generator, steps_per_epoch=len(X_train) // batch_size, epochs=epochs)

# Function to visualize and save Segmented truth masks for all images
def visualize_and_save_segmented_truth(images, masks, filenames, image_size, save_folder):
    for i in range(len(images)):
        plt.figure(figsize=(10, 10))

        plt.title(f'Segmented Image Mask - Image {filenames[i]}')
        plt.imshow(cv2.resize(masks[i], (image_size, image_size)).squeeze(), cmap='gray')

        # Save the Segmented mask
        mask_filename = os.path.join(save_folder, f'{filenames[i]}')
        cv2.imwrite(mask_filename, cv2.resize(masks[i], (image_size, image_size)).squeeze())

        plt.show()

# Combine training and testing data
X_combined = np.concatenate((X_train, X_test), axis=0)
y_combined = np.concatenate((y_train, y_test), axis=0)
filenames_combined = filenames_train + filenames_test

# Visualize and save all Segmented mask
visualize_and_save_segmented_truth(X_combined, y_combined, filenames_combined, image_size, mask_save_folder)